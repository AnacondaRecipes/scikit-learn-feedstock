From af3056b4c2fe12fecb7039f66845de29b705adbb Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 29 Sep 2022 15:33:05 +0200
Subject: [PATCH 01/06] MAINT use nanmin to replace nan by finite values in
 ranking of SearchCV

---
 sklearn/model_selection/_search.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 37b26eb1c72d3..11799fa0c47f7 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -968,7 +968,7 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
                 # when input is nan, scipy >= 1.10 rankdata returns nan. To
                 # keep previous behaviour nans are set to be smaller than the
                 # minimum value in the array before ranking
-                min_array_means = min(array_means) - 1
+                min_array_means = np.nanmin(array_means) - 1
                 array_means = np.nan_to_num(array_means, copy=True, nan=min_array_means)
                 rank_result = rankdata(-array_means, method="min")
                 rank_result = np.asarray(rank_result, dtype=np.int32)

From c7363b631a9b9f6721409d264a4878210cd94b95 Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 29 Sep 2022 15:40:00 +0200
Subject: [PATCH 02/06] handle the case with only nan values

---
 sklearn/model_selection/_search.py | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 11799fa0c47f7..81ef331458f68 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -969,6 +969,9 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
                 # keep previous behaviour nans are set to be smaller than the
                 # minimum value in the array before ranking
                 min_array_means = np.nanmin(array_means) - 1
+                if np.isnan(min_array_means):
+                    # all values in array_means are nan. Set min_array_means to 0
+                    min_array_means = 0
                 array_means = np.nan_to_num(array_means, copy=True, nan=min_array_means)
                 rank_result = rankdata(-array_means, method="min")
                 rank_result = np.asarray(rank_result, dtype=np.int32)

From 88376417ab45ffab03176ee4602b284e724bbe46 Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 29 Sep 2022 20:48:07 +0200
Subject: [PATCH 03/06] catch early the case of all failed fit/scoring
 routinesd

---
 sklearn/model_selection/_search.py | 24 ++++++++++++++----------
 1 file changed, 14 insertions(+), 10 deletions(-)

diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 81ef331458f68..525327d539bbd 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -965,16 +965,20 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
             results["std_%s" % key_name] = array_stds
 
             if rank:
-                # when input is nan, scipy >= 1.10 rankdata returns nan. To
-                # keep previous behaviour nans are set to be smaller than the
-                # minimum value in the array before ranking
-                min_array_means = np.nanmin(array_means) - 1
-                if np.isnan(min_array_means):
-                    # all values in array_means are nan. Set min_array_means to 0
-                    min_array_means = 0
-                array_means = np.nan_to_num(array_means, copy=True, nan=min_array_means)
-                rank_result = rankdata(-array_means, method="min")
-                rank_result = np.asarray(rank_result, dtype=np.int32)
+                # When the fit/scoring fails `array_means` contains NaNs, we
+                # will exclude them from the ranking process and consider them
+                # as ties as worst performers.
+                if np.isnan(array_means).all():
+                    # All fit/scoring routines failed.
+                    rank_result = np.ones_like(array_means, dtype=np.int32)
+                else:
+                    min_array_means = np.nanmin(array_means) - 1
+                    array_means = np.nan_to_num(
+                        array_means, copy=True, nan=min_array_means
+                    )
+                    rank_result = rankdata(-array_means, method="min").astype(
+                        np.int32, copy=False
+                    )
                 results["rank_%s" % key_name] = rank_result
 
         _store("fit_time", out["fit_time"])


From 2861a7bacc949415e900949cad8b1ff523ac7f29 Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 13 Oct 2022 14:49:03 +0200
Subject: [PATCH 04/06] Update sklearn/model_selection/_search.py

Co-authored-by: Olivier Grisel <olivier.grisel@ensta.org>
---
 sklearn/model_selection/_search.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 525327d539bbd..3d067b2767f41 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -967,7 +967,7 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
             if rank:
                 # When the fit/scoring fails `array_means` contains NaNs, we
                 # will exclude them from the ranking process and consider them
-                # as ties as worst performers.
+                # as tied with the worst performers.
                 if np.isnan(array_means).all():
                     # All fit/scoring routines failed.
                     rank_result = np.ones_like(array_means, dtype=np.int32)

From 78a51fa90d0d5825a20197dcc99242fb7203e11b Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 13 Oct 2022 14:52:35 +0200
Subject: [PATCH 05/06] thomas comment

---
 sklearn/model_selection/_search.py | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 3d067b2767f41..6ccbae2abc611 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -973,9 +973,7 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
                     rank_result = np.ones_like(array_means, dtype=np.int32)
                 else:
                     min_array_means = np.nanmin(array_means) - 1
-                    array_means = np.nan_to_num(
-                        array_means, copy=True, nan=min_array_means
-                    )
+                    array_means = np.nan_to_num(array_means, nan=min_array_means)
                     rank_result = rankdata(-array_means, method="min").astype(
                         np.int32, copy=False
                     )

From 17035bd689463e6e9599ac3318872348c75cbd10 Mon Sep 17 00:00:00 2001
From: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date: Thu, 13 Oct 2022 16:42:11 +0200
Subject: [PATCH 06/06] TST add a check for new behaviour

---
 sklearn/model_selection/tests/test_search.py | 11 +++++++++--
 1 file changed, 9 insertions(+), 2 deletions(-)

diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
index b86dfbd77846f..194a5d7ea3ca1 100644
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -1981,10 +1981,10 @@ def get_n_splits(self, *args, **kw):
 @pytest.mark.parametrize(
     "SearchCV, specialized_params",
     [
-        (GridSearchCV, {"param_grid": {"max_depth": [2, 3]}}),
+        (GridSearchCV, {"param_grid": {"max_depth": [2, 3, 5, 8]}}),
         (
             RandomizedSearchCV,
-            {"param_distributions": {"max_depth": [2, 3]}, "n_iter": 2},
+            {"param_distributions": {"max_depth": [2, 3, 5, 8]}, "n_iter": 4},
         ),
     ],
 )
@@ -2025,6 +2025,13 @@ def __call__(self, estimator, X, y):
     for msg, dataset in zip(warn_msg, set_with_warning):
         assert f"One or more of the {dataset} scores are non-finite" in str(msg.message)
 
+    # all non-finite scores should be equally ranked last
+    last_rank = grid.cv_results_["rank_test_score"].max()
+    non_finite_mask = np.isnan(grid.cv_results_["mean_test_score"])
+    assert_array_equal(grid.cv_results_["rank_test_score"][non_finite_mask], last_rank)
+    # all finite scores should be better ranked than the non-finite scores
+    assert np.all(grid.cv_results_["rank_test_score"][~non_finite_mask] < last_rank)
+
 
 def test_callable_multimetric_confusion_matrix():
     # Test callable with many metrics inserts the correct names and metrics
